{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "import tiktoken\n",
    "\n",
    "#Retrivers\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "from dotenv import dotenv_values\n",
    "secret=dotenv_values(\".env\")\n",
    "secret[\"OPENAI_API_KEY\"]\n",
    "\n",
    "\n",
    "openai.api_key  = secret[\"OPENAI_API_KEY\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('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',\n",
       " '9b7203fb-987c-4a1a-8084-4e4606af6450')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.api_key, secret['PINCONE_API_KEY']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "728"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "\n",
    "pdf_paths = glob.glob(\"data/*.pdf\")\n",
    "\n",
    "# Replace double backslashes with single backslashes and print\n",
    "loaders=[]\n",
    "for pdf_path in pdf_paths:\n",
    "   loaders.append(PyPDFLoader(pdf_path.replace(\"\\\\\", \"/\")))\n",
    "doc=[]\n",
    "for loader in loaders:\n",
    "    doc.extend(loader.load())\n",
    "\n",
    "len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'data/XGBoost with Python Gradient Boosted Trees with XGBoost and scikit-learn (Jason Brownlee) (z-lib.org).pdf',\n",
       " 'page': 97}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[710].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of pages in the document 728\n",
      "First 100 char of first 1 page: 7.6 Local Regression 303\n",
      "20 30 40 50 60 70 800 50 100 200 300AgeWageSmoothing Spline16 Degrees of Freedom6.8 Degrees of Freedom (LOOCV)\n",
      "FIGURE 7.8. Smoothing spline fits to the Wagedata. The red curve results\n",
      "from specifying 16effective degrees of freedom. For the blue curve, Î»was found\n",
      "automatically by leave-one-out cross-validation, which resulted in 6.8effective\n",
      "degrees of freedom.\n",
      "is preferable, since in general simpler models are better unless the data\n",
      "provides evidence in support of a more complex model.\n",
      "7.6 Local Regression\n",
      "Local regression is a different approach for fitting flexible non-linear func-local\n",
      "regressiontions, which involves computing the fit at a target point x0using only the\n",
      "nearby training observations. Figure 7.9illustrates the idea on some simu-\n",
      "lated data, with one target point near 0.4, and another near the boundary\n",
      "at0.05. In this figure the blue line represents the function f(x)from which\n",
      "the data were generated, and the light orange line corresponds to the\n"
     ]
    }
   ],
   "source": [
    "no_pages=len(doc)\n",
    "print(f\"No of pages in the document {no_pages}\")\n",
    "\n",
    "first_pg=doc[310].page_content[0:1000] # First 100 char of first 1 page\n",
    "print (f\"First 100 char of first 1 page: {first_pg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1512"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "chunk_size=1500\n",
    "chunk_overlap=200\n",
    "\n",
    "r_splitter=RecursiveCharacterTextSplitter(chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"]\n",
    "    )\n",
    "\n",
    "splits=r_splitter.split_documents(doc)\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding & Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.vectorstores import Chroma\n",
    "# from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "# persist_directory = 'data/chroma/'\n",
    "# embedding = OpenAIEmbeddings()\n",
    "# vectordb = Chroma.from_documents(\n",
    "#     documents=splits,\n",
    "#     embedding=embedding,\n",
    "#     persist_directory=persist_directory\n",
    "# )\n",
    "# print(vectordb._collection.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import pinecone\n",
    "embedding = OpenAIEmbeddings()\n",
    "#initiaize pinecon\n",
    "pinecone.init(\n",
    "    api_key=secret['PINCONE_API_KEY'],\n",
    "    environment=secret['PINCONE_ENV']\n",
    "    \n",
    "    \n",
    ")\n",
    "index_name= 'multi-source-qna'\n",
    "\n",
    "\n",
    "# The OpenAI embedding model `text-embedding-ada-002 uses 1536 dimensions`\n",
    "vectordb = Pinecone.from_documents(splits, embedding, index_name=index_name)\n",
    "\n",
    "# if you already have an index, you can load it like this\n",
    "# docsearch = Pinecone.from_existing_index(index_name, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 77.0, 'source': 'data/ISLP_website.pdf'}\n",
      "{'page': 82.0, 'source': 'data/ISLP_website.pdf'}\n",
      "{'page': 142.0, 'source': 'data/ISLP_website.pdf'}\n",
      "{'page': 126.0, 'source': 'data/ISLP_website.pdf'}\n",
      "{'page': 98.0, 'source': 'data/ISLP_website.pdf'}\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "query=\" What is linear regression ?\"\n",
    "docs=vectordb.similarity_search(query,k=5)\n",
    "for doc in docs:\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "An introduction to XGBoost parameters and heuristics for good parameter values. How to tune the number and size of trees in a model. How to tune the learning rate and number of trees in a model. How to tune the sampling rates in stochastic variation of the algorithm.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "\"XGBoost is an algorithm that has recently been dominating applied machine learning and Kaggle competitions for structured or tabular data. XGBoost is an implementation of gradient boosted decision trees designed for speed and performance.\"\n"
     ]
    }
   ],
   "source": [
    "# use max_marginal_relevance_search directly:\n",
    "# found_docs = vectordb.max_marginal_relevance_search(query, k=2, fetch_k=10)\n",
    "# for i, doc in enumerate(found_docs):\n",
    "#     print(f\"{i + 1}.\", doc.page_content, \"\\n\")\n",
    "\n",
    "# Using Compression retrivevel technique\n",
    "def pretty_print_docs(docs):\n",
    "    print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]))\n",
    "\n",
    "\n",
    "# Wrap our vectorstore\n",
    "llm = OpenAI(temperature=0)\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever(search_type = \"mmr\")\n",
    ")\n",
    "\n",
    "query=\" What is xgboost tips and tricks ?\"\n",
    "compressed_docs = compression_retriever.get_relevant_documents(query)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
