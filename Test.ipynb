{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "import tiktoken\n",
    "#Reading doc file\n",
    "from langchain.document_loaders import Docx2txtLoader\n",
    "#Reading ppt file\n",
    "from langchain.document_loaders import UnstructuredPowerPointLoader\n",
    "# Reading pdf\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "# # Reading jpg\n",
    "# from langchain.document_loaders.image import UnstructuredImageLoader\n",
    "\n",
    "\n",
    "\n",
    "#Retrivers\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "import glob\n",
    "\n",
    "\n",
    "from dotenv import dotenv_values\n",
    "secret=dotenv_values(\".env\")\n",
    "secret[\"OPENAI_API_KEY\"]\n",
    "\n",
    "\n",
    "\n",
    "openai.api_key  = secret[\"OPENAI_API_KEY\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "283"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "paths_pdf = glob.glob(\"data/*.pdf\")\n",
    "paths_word = glob.glob(\"data/*.docx\")\n",
    "paths_ppt = glob.glob(\"data/*.pptx\")\n",
    "paths_jpg=glob.glob(\"data/*.jpg\")\n",
    "\n",
    "#**********************##\\\n",
    "loaders=[]\n",
    "doc=[]\n",
    "\n",
    "for pdf_path in paths_pdf:\n",
    "       loaders.append(PyPDFLoader(pdf_path.replace(\"\\\\\", \"/\")))\n",
    "for word_path in paths_word:\n",
    "       loaders.append(Docx2txtLoader(word_path.replace(\"\\\\\", \"/\")))\n",
    "for ppt_path in paths_ppt:\n",
    "    loaders.append(UnstructuredPowerPointLoader(ppt_path.replace(\"\\\\\", \"/\")))\n",
    "# for jpg_path in paths_jpg:\n",
    "#     loaders.append(UnstructuredImageLoader(jpg_path.replace(\"\\\\\", \"/\")))\n",
    "    \n",
    "for loader in loaders:\n",
    "    doc.extend(loader.load())\n",
    "\n",
    "len(doc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "283"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<langchain.document_loaders.pdf.PyPDFLoader at 0x12b369f1f10>,\n",
       " <langchain.document_loaders.pdf.PyPDFLoader at 0x12b2c70e6d0>,\n",
       " <langchain.document_loaders.word_document.Docx2txtLoader at 0x12b369f1810>,\n",
       " <langchain.document_loaders.powerpoint.UnstructuredPowerPointLoader at 0x12b369f2150>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'data/SQLNotesForProfessionals.pdf', 'page': 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[1].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of pages in the document 283\n",
      "First 100 char of first 1 page: 18.3. Python Machine Learning 109\n",
      "Section 8.6 Boosting, page 203 and Section 14.5 Stochastic Gradient Boosting, page 390,\n",
      "inApplied Predictive Modeling .\n",
      "http://www.amazon.com/dp/1461468485?tag=inspiredalgor-20\n",
      "Section 16.4 Boosting, page 556, Machine Learning: A Probabilistic Perspective .\n",
      "http://www.amazon.com/dp/0262018020?tag=inspiredalgor-20\n",
      "Chapter 10 Boosting and Additive Trees, page 337, The Elements of Statistical Learning:\n",
      "Data Mining, Inference, and Prediction .\n",
      "http://www.amazon.com/dp/0387848576?tag=inspiredalgor-20\n",
      "18.3 Python Machine Learning\n",
      "Python is a growing platform for applied machine learning. The strong attraction is because\n",
      "Python is a fully featured programming language (unlike R) and as such you can use the same\n",
      "code and libraries in developing your model as you use to deploy the model into operations.\n",
      "The premier machine learning library in Python is scikit-learn built on top of SciPy.\n",
      "Visit the scikit-learn home page to learn more about the library and i\n"
     ]
    }
   ],
   "source": [
    "no_pages=len(doc)\n",
    "print(f\"No of pages in the document {no_pages}\")\n",
    "\n",
    "first_pg=doc[280].page_content[0:1000] # First 100 char of first 1 page\n",
    "print (f\"First 100 char of first 1 page: {first_pg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "chunk_size=1500\n",
    "chunk_overlap=200\n",
    "\n",
    "r_splitter=RecursiveCharacterTextSplitter(chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"]\n",
    "    )\n",
    "\n",
    "splits=r_splitter.split_documents(doc)\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding & Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON_PROJECTS\\LLMs\\Multisource_QnA_LLM\\venv\\Lib\\site-packages\\pinecone\\index.py:4: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "#USE BELOW CODE ONLY WHILE CREATING A NEW VECTOR STORE.\n",
    "\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import pinecone\n",
    "embedding = OpenAIEmbeddings()\n",
    "#initiaize pinecon\n",
    "pinecone.init(\n",
    "    api_key=secret['PINCONE_API_KEY'],\n",
    "    environment=secret['PINCONE_ENV']\n",
    "    \n",
    "    \n",
    ")\n",
    "index_name= 'multi-source-qna'\n",
    "\n",
    "\n",
    "# The OpenAI embedding model `text-embedding-ada-002 uses 1536 dimensions`\n",
    "vectordb = Pinecone.from_documents(splits, embedding, index_name=index_name)\n",
    "\n",
    "# if you already have an index, you can load it like thisa\n",
    "# docsearch = Pinecone.from_existing_index(index_name, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 92.0, 'source': 'data/SQLNotesForProfessionals.pdf'}\n",
      "{'page': 8.0, 'source': 'data/SQLNotesForProfessionals.pdf'}\n",
      "{'page': 152.0, 'source': 'data/SQLNotesForProfessionals.pdf'}\n",
      "{'page': 1.0, 'source': 'data/SQLNotesForProfessionals.pdf'}\n",
      "{'page': 3.0, 'source': 'data/SQLNotesForProfessionals.pdf'}\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "query=\" What is linear regression and How to alter table in SQL?\"\n",
    "docs=vectordb.similarity_search(query,k=5)\n",
    "for doc in docs:\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# use max_marginal_relevance_search directly:\n",
    "# found_docs = vectordb.max_marginal_relevance_search(query, k=2, fetch_k=10)\n",
    "# for i, doc in enumerate(found_docs):\n",
    "#     print(f\"{i + 1}.\", doc.page_content, \"\\n\")\n",
    "\n",
    "# Using Compression retrivevel technique\n",
    "def pretty_print_docs(docs):\n",
    "    print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]))\n",
    "\n",
    "\n",
    "# Wrap our vectorstore\n",
    "llm = OpenAI(temperature=0)\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever(search_type = \"mmr\")\n",
    ")\n",
    "\n",
    "# query=\" What is xgboost tips and tricks ?\"\n",
    "query=\"What is black hole?\"\n",
    "\n",
    "compressed_docs = compression_retriever.get_relevant_documents(query,k=5)\n",
    "pretty_print_docs(compressed_docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QnA gpt model intialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AI governance refers to the set of policies, regulations, and ethical frameworks that are put in place to guide the development, deployment, and use of artificial intelligence (AI) technologies. It involves addressing issues such as accountability, transparency, fairness, privacy, and security in AI systems. AI governance aims to ensure that AI is developed and used in a responsible and beneficial manner, while also mitigating potential risks and negative impacts.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-3.5-turbo\",temperature=0)\n",
    "\n",
    "# Import retrieval QA chain\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain= RetrievalQA.from_chain_type(llm,\n",
    "                                      retriever=compression_retriever)\n",
    "\n",
    "query=\" What is AI governance?\"\n",
    "\n",
    "result=qa_chain({'query':query})\n",
    "\n",
    "result['result']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Promttemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Build prompt\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know,\n",
    "don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "QA_Chain_Prompt=PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON_PROJECTS\\LLMs\\Multisource_QnA_LLM\\venv\\Lib\\site-packages\\langchain\\chains\\llm.py:279: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Different AIML strategies include building a continuous learning program for employees, defining metrics, measuring and analyzing data, identifying areas for improvement, and incorporating feedback. Thanks for asking!'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Running Chain again\n",
    "qa_chain=RetrievalQA.from_chain_type(llm,\n",
    "                            retriever=compression_retriever,\n",
    "                            return_source_documents=True, # this will let us ins pect document we retrieve \n",
    "                            chain_type_kwargs={\"prompt\":QA_Chain_Prompt}\n",
    "                            \n",
    ")\n",
    "\n",
    "\n",
    "query=\"What are different AIML strategies ?\"\n",
    "\n",
    "# result=qa_chain({'query':query})\n",
    "result=qa_chain({'query':query})\n",
    "\n",
    "\n",
    "result['result']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retriever QA chain using Map reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON_PROJECTS\\LLMs\\Multisource_QnA_LLM\\venv\\Lib\\site-packages\\langchain\\chains\\llm.py:279: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': ' What are different AIML strategies ?',\n",
       " 'result': \"I'm sorry, but the given portion of the document does not provide any information about different AIML strategies.\"}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain_mr=RetrievalQA.from_chain_type(llm,\n",
    "                                        retriever=compression_retriever,\n",
    "                                        chain_type=\"map_reduce\")\n",
    "query=\" What are different AIML strategies ?\"\n",
    "\n",
    "# result=qa_chain({'query':query})\n",
    "result=qa_chain_mr({'query':query})\n",
    "\n",
    "\n",
    "result['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In addition to the strategies mentioned earlier, when implementing AIML, it is important to consider the available tools and technologies. Here are some additional considerations:\\n\\n1. Research available AIML tools and technologies: There are numerous AIML tools and frameworks available, such as TensorFlow, PyTorch, scikit-learn, and IBM Watson. Researching and understanding the features, capabilities, and limitations of these tools can help in selecting the most suitable one for your specific needs.\\n\\n2. Choose the right tool or technology: Consider factors like the complexity of your problem, the size of your dataset, the scalability requirements, and the programming language you are comfortable with. Each tool or technology may have its own strengths and weaknesses, so choose the one that aligns with your requirements.\\n\\n3. Consider the learning curve: Some AIML tools and technologies may have a steeper learning curve than others. Evaluate the complexity of the tool and the availability of learning resources like documentation, tutorials, and community support. Consider the expertise and skill level of your team and choose a tool that can be effectively adopted and utilized.\\n\\n4. Evaluate vendor support: If you are considering using a commercial AIML tool or technology, evaluate the level of vendor support available. Look for factors like documentation, customer support, regular updates, and a strong user community. Good vendor support can be crucial in resolving issues and ensuring the smooth implementation of AIML strategies.\\n\\nBy considering these additional factors, you can make a more informed decision when choosing and implementing AIML strategies within your organization.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CHain type refine\n",
    "\n",
    "qa_chain_mr=RetrievalQA.from_chain_type(llm,\n",
    "                                        retriever=compression_retriever,\n",
    "                                        chain_type=\"refine\")\n",
    "query=\" What are different AIML strategies ?\"\n",
    "\n",
    "result=qa_chain_mr({'query':query})\n",
    "\n",
    "\n",
    "result['result']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refine chain type qa chain seems to be working good compared to rest of the technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHATBOT- Adding Memrory for the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MEMORY\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': ' What are different AIML strategies ?',\n",
       " 'chat_history': [HumanMessage(content=' What are different AIML strategies ?', additional_kwargs={}, example=False),\n",
       "  AIMessage(content=\"In addition to the strategies mentioned earlier, there are some additional considerations when implementing AIML:\\n\\n1. Research available AIML tools and technologies: It is important to explore the various tools and technologies available in the market for AIML implementation. This includes frameworks, libraries, and platforms that can support your specific requirements.\\n\\n2. Choose the right tool or technology: Once you have researched the available options, carefully evaluate and choose the tool or technology that best aligns with your organization's needs. Consider factors such as scalability, compatibility with existing systems, ease of integration, and the specific AIML capabilities offered.\\n\\n3. Consider the learning curve: Implementing AIML may require learning new technologies and concepts. Consider the learning curve associated with the chosen tool or technology and assess whether your team has the necessary skills or if additional training is required.\\n\\n4. Evaluate vendor support: When selecting a tool or technology, consider the level of support provided by the vendor. This includes factors such as documentation, community support, and availability of technical assistance. It is important to have reliable support channels in case any issues or challenges arise during implementation.\\n\\nBy considering these additional factors, you can ensure a more comprehensive and informed approach to implementing AIML strategies within your organization.\", additional_kwargs={}, example=False),\n",
       "  HumanMessage(content=' What are different AIML strategies ?', additional_kwargs={}, example=False),\n",
       "  AIMessage(content=\"When implementing AIML strategies, the following factors should be considered, including the additional context provided:\\n\\n1. Assessing data readiness: Evaluate the readiness of your data for AIML implementation. This involves assessing the quality, relevance, accuracy, completeness, consistency, and timeliness of the available data.\\n\\n2. Identifying data sources: Identify all the sources of data that your organization currently has. This includes structured and unstructured data from various internal and external sources.\\n\\n3. Evaluating data quality: Evaluate the quality of the data by considering factors such as data accuracy, consistency, and reliability. Identify any data gaps or inconsistencies that may affect the effectiveness of the AIML strategies.\\n\\n4. Making data usable for AIML: Prepare the data for AIML implementation by performing data cleansing, normalization, and transformation. This ensures that the data is in a format that can be effectively utilized by the AIML algorithms and models.\\n\\n5. Ensuring data privacy and security: Implement appropriate data privacy and security protocols to protect sensitive information. Ensure compliance with relevant regulations and establish measures to safeguard data throughout the AIML process.\\n\\n6. Establishing data governance: Establish data governance policies and procedures to ensure proper management, control, and accountability of the data used in AIML strategies. This includes defining roles and responsibilities, data access controls, and data lifecycle management.\\n\\n7. Define metrics: It's essential to define metrics that align with the expected outcomes. These metrics could be in terms of business impact, user experience, or technical performance.\\n\\n8. Measure and analyze: Once the metrics are defined, it's important to measure and analyze the data to evaluate the effectiveness of the solution. This includes comparing the actual results against the expected outcomes and identifying any deviations.\\n\\n9. Identify areas for improvement: Based on the analysis, identify areas for improvement and prioritize them based on their impact and feasibility. This could involve refining the existing solution, adding new features, or addressing any technical or operational challenges.\\n\\n10. Incorporate feedback: It's important to incorporate feedback from users, stakeholders, and subject matter experts to ensure that the solution meets their requirements and expectations. This feedback could be obtained through surveys, user testing, or feedback mechanisms integrated into the solution.\\n\\nBy considering these factors, organizations can effectively implement AIML strategies while ensuring the availability, quality, and security of the data used.\", additional_kwargs={}, example=False),\n",
       "  HumanMessage(content='Can you explain any one of the strategy?', additional_kwargs={}, example=False),\n",
       "  AIMessage(content=\"The additional context provided is indeed useful for refining the original answer. Here's an updated response:\\n\\nOne of the AIML strategies mentioned in the context is defining metrics. Defining metrics is crucial for evaluating the success and effectiveness of an AI or machine learning project. However, before defining metrics, it is important to consider several factors related to data management and governance.\\n\\nFirstly, organizations need to identify all the sources of data they currently possess and assess their quality and relevance to the AIML objective. This includes structured data from databases and spreadsheets, as well as unstructured data from sources like social media, customer feedback, and sensor data.\\n\\nData quality plays a critical role in AIML projects. It is essential to evaluate the accuracy, completeness, consistency, and timeliness of the data, while also identifying any gaps or inconsistencies. Data cleansing, normalization, and transformation may be necessary to make the data usable for AIML purposes.\\n\\nFurthermore, organizations must prioritize data privacy and security. It is crucial to have protocols in place to protect sensitive information and mitigate risks such as data breaches, hacking, and unauthorized access.\\n\\nEstablishing data governance policies and procedures is also essential. This involves defining roles and responsibilities for data management, setting data quality standards, and implementing processes for data lifecycle management. By ensuring consistent data management practices across the organization, data governance helps maintain data integrity and reliability.\\n\\nOnce these data management and governance aspects are addressed, organizations can proceed with defining metrics that align with their AIML objectives. These metrics will enable them to measure the impact and value generated by the AI or machine learning solutions, and make informed decisions for further improvements or optimizations.\", additional_kwargs={}, example=False),\n",
       "  HumanMessage(content=' What are different AIML strategies ?', additional_kwargs={}, example=False),\n",
       "  AIMessage(content=\"The original answer already covers most of the important factors to consider when implementing AIML strategies. However, based on the new context provided, the answer can be refined to include the additional factors mentioned:\\n\\n1. Define metrics: It's essential to define metrics that align with the expected outcomes. These metrics could be in terms of business impact, user experience, or technical performance.\\n\\n2. Measure and analyze: Once the metrics are defined, it's important to measure and analyze the data to evaluate the effectiveness of the solution. This includes comparing the actual results against the expected outcomes and identifying any deviations.\\n\\n3. Identify areas for improvement: Based on the analysis, identify areas for improvement and prioritize them based on their impact and feasibility. This could involve refining the existing solution, adding new features, or addressing any technical or operational challenges.\\n\\n4. Incorporate feedback: It's important to incorporate feedback from users, stakeholders, and subject matter experts to ensure that the solution meets their requirements and expectations. This feedback could be obtained through surveys, user testing, or feedback mechanisms integrated into the solution.\\n\\nBy considering these additional factors, organizations can ensure that their AIML strategies are aligned with the desired outcomes, continuously improved based on data analysis and feedback, and effectively measure the impact of the implemented solutions.\", additional_kwargs={}, example=False)],\n",
       " 'answer': \"The original answer already covers most of the important factors to consider when implementing AIML strategies. However, based on the new context provided, the answer can be refined to include the additional factors mentioned:\\n\\n1. Define metrics: It's essential to define metrics that align with the expected outcomes. These metrics could be in terms of business impact, user experience, or technical performance.\\n\\n2. Measure and analyze: Once the metrics are defined, it's important to measure and analyze the data to evaluate the effectiveness of the solution. This includes comparing the actual results against the expected outcomes and identifying any deviations.\\n\\n3. Identify areas for improvement: Based on the analysis, identify areas for improvement and prioritize them based on their impact and feasibility. This could involve refining the existing solution, adding new features, or addressing any technical or operational challenges.\\n\\n4. Incorporate feedback: It's important to incorporate feedback from users, stakeholders, and subject matter experts to ensure that the solution meets their requirements and expectations. This feedback could be obtained through surveys, user testing, or feedback mechanisms integrated into the solution.\\n\\nBy considering these additional factors, organizations can ensure that their AIML strategies are aligned with the desired outcomes, continuously improved based on data analysis and feedback, and effectively measure the impact of the implemented solutions.\"}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "retriever=compression_retriever\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    chain_type='refine',\n",
    "\n",
    ")\n",
    "\n",
    "query=\" What are different AIML strategies ?\"\n",
    "\n",
    "result=qa({'question':query})\n",
    "\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON_PROJECTS\\LLMs\\Multisource_QnA_LLM\\venv\\Lib\\site-packages\\langchain\\chains\\llm.py:279: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The additional context provided is indeed useful for refining the original answer. Here's an updated response:\\n\\nOne of the AIML strategies mentioned in the context is defining metrics. Defining metrics is crucial for evaluating the success and effectiveness of an AI or machine learning project. However, before defining metrics, it is important to consider several factors related to data management and governance.\\n\\nFirstly, organizations need to identify all the sources of data they currently possess and assess their quality and relevance to the AIML objective. This includes structured data from databases and spreadsheets, as well as unstructured data from sources like social media, customer feedback, and sensor data.\\n\\nData quality plays a critical role in AIML projects. It is essential to evaluate the accuracy, completeness, consistency, and timeliness of the data, while also identifying any gaps or inconsistencies. Data cleansing, normalization, and transformation may be necessary to make the data usable for AIML purposes.\\n\\nFurthermore, organizations must prioritize data privacy and security. It is crucial to have protocols in place to protect sensitive information and mitigate risks such as data breaches, hacking, and unauthorized access.\\n\\nEstablishing data governance policies and procedures is also essential. This involves defining roles and responsibilities for data management, setting data quality standards, and implementing processes for data lifecycle management. By ensuring consistent data management practices across the organization, data governance helps maintain data integrity and reliability.\\n\\nOnce these data management and governance aspects are addressed, organizations can proceed with defining metrics that align with their AIML objectives. These metrics will enable them to measure the impact and value generated by the AI or machine learning solutions, and make informed decisions for further improvements or optimizations.\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=\"Can you explain any one of the strategy?\"\n",
    "result=qa({'question':query})\n",
    "\n",
    "\n",
    "result['answer']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
